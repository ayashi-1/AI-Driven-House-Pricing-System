# -*- coding: utf-8 -*-

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zXKgSvOa_7JyeV6QYfbJfb7aaLz6Suys

####Sangeeta kumari
####Ayashi
####Rajshri
####Jagriti Singh

# **AI - DRIVEN HOME PRICING SYSTEM**
Load the dataset from "/content/NY-House-Dataset (1).csv", then perform data cleaning and preprocessing steps including handling missing values and duplicates. Finally, display the cleaned data.

# Load the data
Load the dataset into a pandas DataFrame.
"""

import pandas as pd
from google.colab import files
import io

uploaded = files.upload()


df = pd.read_csv('/content/NY-House-Dataset (1).csv')

"""# Data Cleaning and Processing

## Explore the data

Display the first few rows, check the data types, and look at descriptive statistics.
"""

display(df.head())
display(df.info())
display(df.describe())

"""## Handle missing values
Check for and address any missing values in the dataset.

"""

missing_values = df.isnull().sum()
print("Missing values per column:")
print(missing_values)

"""## Handle duplicates

### Subtask:
Check for and remove any duplicate rows.

"""

print("Number of duplicate rows before removal:", df.duplicated().sum())
df.drop_duplicates(inplace=True)
print("Number of duplicate rows after removal:", df.duplicated().sum())

"""# Exploratory Data Analysis

## Visualize the data

Create some visualizations to understand the distribution of key features and their relationship with the price.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# 1. Histogram of 'PRICE'
plt.figure(figsize=(10, 6))
sns.histplot(df['PRICE'], kde=True)
plt.title('Distribution of Property Prices')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

# 2. Scatter plot of 'PROPERTYSQFT' vs 'PRICE'
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='PROPERTYSQFT', y='PRICE', alpha=0.6)
plt.title('Property Square Footage vs. Price')
plt.xlabel('Property Square Footage')
plt.ylabel('Price')
plt.show()

# 3. Box plot of 'PRICE' by 'BEDS'
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='BEDS', y='PRICE')
plt.title('Price Distribution by Number of Bedrooms')
plt.xlabel('Number of Bedrooms')
plt.ylabel('Price')
plt.show()

# 4. Box plot of 'PRICE' by 'BATH'
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='BATH', y='PRICE')
plt.title('Price Distribution by Number of Bathrooms')
plt.xlabel('Number of Bathrooms')
plt.ylabel('Price')
plt.show()

# 5. Count plot of the 'TYPE' column
plt.figure(figsize=(12, 6))
sns.countplot(y='TYPE', data=df, order = df['TYPE'].value_counts().index)
plt.title('Distribution of Property Types')
plt.xlabel('Count')
plt.ylabel('Property Type')
plt.show()

# Stacked bar chart of 'TYPE' by 'LOCALITY'
plt.figure(figsize=(14, 8))
sns.histplot(data=df, x='LOCALITY', hue='TYPE', multiple='stack', shrink=.8)
plt.title('Stacked Distribution of Property Types by Locality')
plt.xlabel('Locality')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# correlation heatmap of numerical features
numerical_cols = df.select_dtypes(include=np.number).columns

correlation_matrix = df[numerical_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""
Visualize the price distribution on a map using latitude and longitude."""

import folium

# Create a base map centered around New York
m = folium.Map(location=[df['LATITUDE'].mean(), df['LONGITUDE'].mean()], zoom_start=10)

for idx, row in df.iterrows():
    folium.Marker(
        location=[row['LATITUDE'], row['LONGITUDE']],
        popup=f"Price: ${row['PRICE']:,.2f}",
        icon=folium.Icon(color='blue', icon='home')
    ).add_to(m)

display(m)

"""
Visualize the price distribution across different localities and sublocalities using box plots."""

# Box plot of 'PRICE' by 'LOCALITY'
plt.figure(figsize=(14, 7))
sns.boxplot(data=df, x='LOCALITY', y='PRICE')
plt.title('Price Distribution by Locality')
plt.xlabel('Locality')
plt.ylabel('Price')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Box plot of 'PRICE' by 'SUBLOCALITY' (showing top N sublocalities for clarity)
top_sublocalities = df['SUBLOCALITY'].value_counts().nlargest(10).index
df_top_sublocalities = df[df['SUBLOCALITY'].isin(top_sublocalities)]

plt.figure(figsize=(14, 7))
sns.boxplot(data=df_top_sublocalities, x='SUBLOCALITY', y='PRICE')
plt.title('Price Distribution by Top 10 Sublocalities')
plt.xlabel('Sublocality')
plt.ylabel('Price')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""
Visualize the distribution of brokers using a count plot."""

# Count plot of the 'BROKERTITLE' column (showing top N brokers for clarity)
top_brokers = df['BROKERTITLE'].value_counts().nlargest(10).index
df_top_brokers = df[df['BROKERTITLE'].isin(top_brokers)]

plt.figure(figsize=(12, 7))
sns.countplot(y='BROKERTITLE', data=df_top_brokers, order = top_brokers)
plt.title('Distribution of Top 10 Brokers')
plt.xlabel('Count')
plt.ylabel('Broker Title')
plt.tight_layout()
plt.show()

"""# Feature engineering

Create new features or transform existing ones if necessary for modeling.

"""

df['BEDS_BATHS_RATIO'] = df.apply(lambda row: row['BEDS'] / row['BATH'] if row['BATH'] != 0 else row['BEDS'], axis=1)

df['TOTAL_ROOMS'] = df['BEDS'] + df['BATH']

df['IS_DOUGLAS_ELLIMAN'] = df['BROKERTITLE'].apply(lambda x: 1 if 'Douglas Elliman' in x else 0)

if (df['PRICE'] == 0).any():
    df['PRICE_log'] = np.log1p(df['PRICE'])
else:
    df['PRICE_log'] = np.log(df['PRICE'])

if (df['PROPERTYSQFT'] == 0).any():
    df['PROPERTYSQFT_log'] = np.log1p(df['PROPERTYSQFT'])
else:
    df['PROPERTYSQFT_log'] = np.log(df['PROPERTYSQFT'])

display(df[['BEDS', 'BATH', 'BEDS_BATHS_RATIO', 'TOTAL_ROOMS', 'BROKERTITLE', 'IS_DOUGLAS_ELLIMAN', 'PRICE', 'PRICE_log', 'PROPERTYSQFT', 'PROPERTYSQFT_log']].head())

"""
Visualize the relationships between BEDS, BATH, PROPERTYSQFT, and PRICE using a pair plot."""

numerical_features = ['BEDS', 'BATH', 'PROPERTYSQFT_log', 'PRICE_log']
sns.pairplot(df[numerical_features])
plt.suptitle('Pair Plot of Numerical Features', y=1.02)
plt.show()

"""# Model Training and Evaluation
Select and train a machine learning model to predict house prices.

"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

features = ['BEDS', 'BATH', 'PROPERTYSQFT_log', 'BEDS_BATHS_RATIO', 'TOTAL_ROOMS', 'IS_DOUGLAS_ELLIMAN']
target = 'PRICE_log'

X = df[features]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.neural_network import MLPRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor

linear_model = LinearRegression()
nn_model = MLPRegressor(random_state=42, max_iter=500)
lgbm_model = LGBMRegressor(random_state=42)
xgb_model = XGBRegressor(random_state=42)
model = RandomForestRegressor(random_state=42)

print("Training Random Forest...")
model.fit(X_train, y_train)
print("Training Linear Regression...")
linear_model.fit(X_train, y_train)
print("Training Neural Network...")
nn_model.fit(X_train, y_train)
print("Training LightGBM...")
lgbm_model.fit(X_train, y_train)
print("Training XGBoost...")
xgb_model.fit(X_train, y_train)

models = {
    "Random Forest": model,
    "Linear Regression": linear_model,
    "Neural Network": nn_model,
    "LightGBM": lgbm_model,
    "XGBoost": xgb_model
}

"""
Evaluate the performance of the trained model.
"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

results = {}

for name, current_model in models.items():
    y_pred = current_model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    results[name] = {"MAE": mae, "MSE": mse, "RMSE": rmse, "R2": r2}

print("\nModel Evaluation Results:")
for name, metrics in results.items():
    print(f"\n{name}:")
    print(f"  Mean Absolute Error (MAE): {metrics['MAE']:.4f}")
    print(f"  Mean Squared Error (MSE): {metrics['MSE']:.4f}")
    print(f"  Root Mean Squared Error (RMSE): {metrics['RMSE']:.4f}")
    print(f"  R-squared (R2): {metrics['R2']:.4f}")

"""
Calculate the average predictions of all models"""

y_pred_rf = models["Random Forest"].predict(X_test)
y_pred_lr = models["Linear Regression"].predict(X_test)
y_pred_nn = models["Neural Network"].predict(X_test)
y_pred_lgbm = models["LightGBM"].predict(X_test)
y_pred_xgb = models["XGBoost"].predict(X_test)

y_pred_ensemble = (y_pred_rf + y_pred_lr + y_pred_nn + y_pred_lgbm + y_pred_xgb) / len(models)

ensemble_mae = mean_absolute_error(y_test, y_pred_ensemble)
ensemble_mse = mean_squared_error(y_test, y_pred_ensemble)
ensemble_rmse = np.sqrt(ensemble_mse)
ensemble_r2 = r2_score(y_test, y_pred_ensemble)

print("\nEnsemble Model Evaluation Results (Averaging):")
print(f"  Mean Absolute Error (MAE): {ensemble_mae:.4f}")
print(f"  Mean Squared Error (MSE): {ensemble_mse:.4f}")
print(f"  Root Mean Squared Error (RMSE): {ensemble_rmse:.4f}")
print(f"  R-squared (R2): {ensemble_r2:.4f}")

all_results = results.copy()
all_results["Averaging Ensemble"] = {
    "MAE": ensemble_mae,
    "MSE": ensemble_mse,
    "RMSE": ensemble_rmse,
    "R2": ensemble_r2
}

all_results_df = pd.DataFrame.from_dict(all_results, orient='index')

print("\nAll Model Evaluation Metrics:")
display(all_results_df)

"""
Visualize the evaluation metrics of all models"""

if 'all_results' not in locals():
    all_results = results.copy()
    all_results["Averaging Ensemble"] = {
        "MAE": ensemble_mae,
        "MSE": ensemble_mse,
        "RMSE": ensemble_rmse,
        "R2": ensemble_r2
    }

all_results_df = pd.DataFrame.from_dict(all_results, orient='index')

# Plotting the metrics
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Comparison of Model Evaluation Metrics', fontsize=16)

# MAE plot
sns.barplot(ax=axes[0, 0], x=all_results_df.index, y='MAE', data=all_results_df)
axes[0, 0].set_title('Mean Absolute Error (MAE)')
axes[0, 0].tick_params(axis='x', rotation=45)

# MSE plot
sns.barplot(ax=axes[0, 1], x=all_results_df.index, y='MSE', data=all_results_df)
axes[0, 1].set_title('Mean Squared Error (MSE)')
axes[0, 1].tick_params(axis='x', rotation=45)

# RMSE plot
sns.barplot(ax=axes[1, 0], x=all_results_df.index, y='RMSE', data=all_results_df)
axes[1, 0].set_title('Root Mean Squared Error (RMSE)')
axes[1, 0].tick_params(axis='x', rotation=45)

# R2 plot
sns.barplot(ax=axes[1, 1], x=all_results_df.index, y='R2', data=all_results_df)
axes[1, 1].set_title('R-squared (R2)')
axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])

"""## Compare Actual vs. Predicted Prices
Display the first 10 actual and predicted prices from all models
"""

if 'y_test' in locals() and 'models' in locals():
    actual_prices_10 = np.expm1(y_test.values[:10]) if 'PRICE_log' in df.columns else y_test.values[:10]

    predictions_data = {'Actual': actual_prices_10}

    for name, current_model in models.items():
        y_pred_10_log = current_model.predict(X_test[:10])
        predictions_data[name] = np.expm1(y_pred_10_log) if 'PRICE_log' in df.columns else y_pred_10_log

    predictions_df = pd.DataFrame(predictions_data)

    for col in predictions_df.columns:
        predictions_df[col] = predictions_df[col].apply(lambda x: f"${x:,.2f}")

    print("\nFirst 10 Actual vs Predicted Prices for All Models:")
    display(predictions_df)

else:
    print("y_test or models dictionary not found. Please run the model training and evaluation cells.")

"""
Visualize actual vs. predicted prices for each model"""

models_to_plot = models.copy()
if 'y_pred_ensemble' in locals():
    models_to_plot["Averaging Ensemble"] = None

num_plots = len(models_to_plot)
n_cols = 2
n_rows = (num_plots + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 5))
axes = axes.flatten()

colors = sns.color_palette('tab10', len(models_to_plot))

for i, (name, current_model) in enumerate(models_to_plot.items()):
    ax = axes[i]

    if name == "Averaging Ensemble":
        y_pred = y_pred_ensemble
        color = 'purple'
    else:
        y_pred = current_model.predict(X_test)
        color = colors[i]

    ax.scatter(y_test, y_pred, alpha=0.5, color=color)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    ax.set_xlabel('Actual Price (log transformed)')
    ax.set_ylabel('Predicted Price (log transformed)')
    ax.set_title(f'{name}: Actual vs Predicted Prices (Log Transformed)')
    ax.grid(True)

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

""" Compare Actual vs. Predicted Prices for the first 10 samples"""

actual_prices_10 = np.expm1(y_test.values[:10])

plot_data = {'Sample Index': range(10), 'Actual Price': actual_prices_10}

for name, current_model in models.items():
    y_pred_10_log = current_model.predict(X_test[:10])
    plot_data[f'{name} Predicted'] = np.expm1(y_pred_10_log)

plot_df = pd.DataFrame(plot_data)

plot_df_melted = plot_df.melt('Sample Index', var_name='Source', value_name='Price')

plt.figure(figsize=(14, 7))
sns.lineplot(data=plot_df_melted, x='Sample Index', y='Price', hue='Source', marker='o')
plt.title('Actual vs Predicted Prices for First 10 Samples (All Models)')
plt.xlabel('Sample Index')
plt.ylabel('Price')
plt.grid(True)
plt.legend(title='Price Source')
plt.show()

"""## Compare top 3 models
 Display the evaluation metrics of top 3 models
"""

sorted_results = sorted(results.items(), key=lambda item: item[1]['R2'], reverse=True)

top_3_models = dict(sorted_results[:3])

results_df = pd.DataFrame.from_dict(top_3_models, orient='index')

print("\nTop 3 Model Evaluation Metrics:")
display(results_df)

import matplotlib.pyplot as plt
import seaborn as sns

# Plotting the metrics for the top 3 models
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Comparison of Top 3 Model Evaluation Metrics', fontsize=16)

# MAE plot
sns.barplot(ax=axes[0, 0], x=results_df.index, y='MAE', data=results_df, palette='viridis')
axes[0, 0].set_title('Mean Absolute Error (MAE)')
axes[0, 0].tick_params(axis='x', rotation=45)

# MSE plot
sns.barplot(ax=axes[0, 1], x=results_df.index, y='MSE', data=results_df, palette='viridis')
axes[0, 1].set_title('Mean Squared Error (MSE)')
axes[0, 1].tick_params(axis='x', rotation=45)

# RMSE plot
sns.barplot(ax=axes[1, 0], x=results_df.index, y='RMSE', data=results_df, palette='viridis')
axes[1, 0].set_title('Root Mean Squared Error (RMSE)')
axes[1, 0].tick_params(axis='x', rotation=45)

# R2 plot
sns.barplot(ax=axes[1, 1], x=results_df.index, y='R2', data=results_df, palette='viridis')
axes[1, 1].set_title('R-squared (R2)')
axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""Display the predictions of the top 3 models"""

import numpy as np

idx = 0

single_feat = X_test.iloc[idx].values.reshape(1, -1)

actual_log = y_test.iloc[idx]

actual_price    = np.expm1(actual_log)

print(f"Actual Price for sample {idx}: ${actual_price:,.2f}")
print("\nPredictions for Top 3 Models:")

for name in top_3_models.keys():
    current_model = models[name]
    pred_log = current_model.predict(single_feat)[0]
    pred_price = np.expm1(pred_log)
    print(f"{name} Predicted:  ${pred_price:,.2f}")

"""# Summary of the Notebook

This notebook performs an AI-driven house pricing system. The steps are as follows:

1.  **Data Loading**: The dataset from "/content/NY-House-Dataset (1).csv" is loaded into a pandas DataFrame.
2.  **Data Cleaning and Processing**: Missing values and duplicate rows are checked and handled.
3.  **Exploratory Data Analysis**: Various visualizations are created to understand the distribution of key features, their relationship with price, price distribution on a map, price distribution across localities and sublocalities, relationships between numerical features using a pair plot, and the distribution of brokers.
4.  **Feature Engineering**: New features like 'BEDS\_BATHS\_RATIO', 'TOTAL\_ROOMS', and 'IS\_DOUGLAS\_ELLIMAN' are created. Logarithmic transformations are applied to 'PRICE' and 'PROPERTYSQFT'.
5.  **Model Training and Evaluation**: Several machine learning models (Linear Regression, Neural Network, LightGBM, XGBoost, and Random Forest) are trained to predict house prices. The models are evaluated using metrics such as MAE, MSE, RMSE, and R2 score. An averaging ensemble model is also created and evaluated. Based on the evaluation metrics, **LightGBM**, **XGBoost**, and **Random Forest** were the top 3 performing models.Based on the evaluation metrics, LightGBM was the best performing individual model.
6.  **Model Comparison**: The evaluation metrics of all models are displayed and visualized. The first 10 actual vs. predicted prices for all models are shown, and actual vs. predicted prices are visualized for each model. The evaluation metrics and predictions of the top 3 models are also displayed.

## Results and Discussion (Summary)

*   **Data:** Loaded, cleaned, and explored a New York house dataset. Handled missing values and duplicates.
*   **Feature Engineering:** Created new features and transformed price and square footage using logarithmic scaling.
*   **Model Performance:** Trained and evaluated Linear Regression, Neural Network, Random Forest, LightGBM, and XGBoost models. LightGBM was the top-performing individual model (R2 ~ 0.60). An averaging ensemble also showed good results.
*   **Key Insights:** Visualizations revealed price distribution is skewed, property size and location significantly impact price, and relationships exist between numerical features. Models generally capture trends but struggle with outliers/high-value properties.
*   **Future Work:** Consider advanced models, external data, and hyperparameter tuning to improve predictions.

This analysis provides a starting point for an AI house pricing system, with LightGBM being a promising model.
"""
